{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\warun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\warun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\warun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the code dataset\n",
    "data = pd.read_csv('code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_snippet</th>\n",
       "      <th>expected_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a = 5\\nb = 0\\nprint(a / b)</td>\n",
       "      <td>ZeroDivisionError on line 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>print(undefined_var)</td>\n",
       "      <td>NameError on line 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x = 10\\nx += '5'</td>\n",
       "      <td>TypeError on line 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['apple', 'banana', 'cherry'][3]</td>\n",
       "      <td>IndexError on line 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class MyClass:\\n    def __init__(self):\\n     ...</td>\n",
       "      <td>AttributeError on line 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>a = '5'\\nb = int('a')\\nresult = a + b</td>\n",
       "      <td>TypeError on line 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>def custom_function(*args):\\n    return args[1...</td>\n",
       "      <td>IndexError on line 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>try:\\n    x = int('abc')\\nexcept ValueError as...</td>\n",
       "      <td>ValueError on line 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>import non_existent_module</td>\n",
       "      <td>ModuleNotFoundError on line 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>result = 5/0</td>\n",
       "      <td>ZeroDivisionError on line 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          code_snippet   \n",
       "0                           a = 5\\nb = 0\\nprint(a / b)  \\\n",
       "1                                 print(undefined_var)   \n",
       "2                                     x = 10\\nx += '5'   \n",
       "3                     ['apple', 'banana', 'cherry'][3]   \n",
       "4    class MyClass:\\n    def __init__(self):\\n     ...   \n",
       "..                                                 ...   \n",
       "431              a = '5'\\nb = int('a')\\nresult = a + b   \n",
       "432  def custom_function(*args):\\n    return args[1...   \n",
       "433  try:\\n    x = int('abc')\\nexcept ValueError as...   \n",
       "434                         import non_existent_module   \n",
       "435                                       result = 5/0   \n",
       "\n",
       "                   expected_output  \n",
       "0      ZeroDivisionError on line 3  \n",
       "1              NameError on line 1  \n",
       "2              TypeError on line 2  \n",
       "3             IndexError on line 1  \n",
       "4         AttributeError on line 3  \n",
       "..                             ...  \n",
       "431            TypeError on line 3  \n",
       "432           IndexError on line 2  \n",
       "433           ValueError on line 2  \n",
       "434  ModuleNotFoundError on line 1  \n",
       "435    ZeroDivisionError on line 1  \n",
       "\n",
       "[436 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the expected_output column\n",
    "label_encoder = LabelEncoder()\n",
    "data['expected_output_encoded'] = label_encoder.fit_transform(data['expected_output'])\n",
    "\n",
    "# Tokenize the code snippets\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['code_snippet'])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text to sequences and pad them to a fixed length\n",
    "input_sequences = tokenizer.texts_to_sequences(data['code_snippet'])\n",
    "padded_sequences = pad_sequences(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['expected_output_encoded'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Use torch.long for multi-class classification\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)  # Use torch.long for multi-class classification\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the LSTM model for multi-class classification\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# Initialize the model for multi-class classification\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "output_dim = len(data['expected_output'].unique())  # Number of unique error types\n",
    "model = LSTMModel(embedding_dim, hidden_dim, total_words, output_dim)\n",
    "\n",
    "# Define loss and optimizer for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8863636363636364\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        output = model(batch_x)\n",
    "        _, predicted_labels = torch.max(output, 1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy for multi-class classification\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'lstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(200, 50)\n",
       "  (lstm): LSTM(50, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = LSTMModel(embedding_dim, hidden_dim, total_words, output_dim)\n",
    "loaded_model.load_state_dict(torch.load('lstm_model.pth'))\n",
    "loaded_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Error: Success\n",
      "5\n",
      "-5\n",
      "Error on line 4: division by zero\n",
      "Error on line 7: invalid syntax (<string>, line 1)\n"
     ]
    }
   ],
   "source": [
    "#predict the error type\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the maximum sequence length used during training\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# Instantiate the model with the same parameters\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "output_dim = len(data['expected_output'].unique())  # Number of unique error types\n",
    "model = LSTMModel(embedding_dim, hidden_dim, total_words, output_dim)\n",
    "\n",
    "# Load the saved model\n",
    "model.load_state_dict(torch.load('lstm_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Function to predict error type for a given code snippet\n",
    "def predict_error(code_snippet, tokenizer):\n",
    "    # Tokenize and pad the code snippet\n",
    "    input_sequence = tokenizer.texts_to_sequences([code_snippet])\n",
    "    padded_sequence = pad_sequences(input_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    input_tensor = torch.tensor(padded_sequence, dtype=torch.long)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "    # Convert the predicted label to the original error type\n",
    "    predicted_error = label_encoder.classes_[predicted_label.item()]\n",
    "    \n",
    "    return predicted_error\n",
    "\n",
    "# Example usage\n",
    "code_to_predict = \"\"\"\n",
    "a = 5\n",
    "b = 0\n",
    "print(a / b)\n",
    "print(a+b)\n",
    "print(b-a)\n",
    "This is a test\n",
    "\"\"\"\n",
    "predicted_error = predict_error(code_to_predict, tokenizer)\n",
    "print(f\"Predicted Error: {predicted_error}\")\n",
    "\n",
    "# Function to get error output using existing tool if model fails to predict\n",
    "def get_error_output(code):\n",
    "    global_vars = {}\n",
    "    error_report = []\n",
    "\n",
    "    for line_number, line in enumerate(code.split('\\n'), 1):\n",
    "        try:\n",
    "            exec(line, global_vars)\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error on line {line_number}: {str(e)}\"\n",
    "            error_report.append(error_message)\n",
    "    \n",
    "    return error_report\n",
    "\n",
    "# Example usage\n",
    "error_output = get_error_output(code_to_predict)\n",
    "for error in error_output:\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
